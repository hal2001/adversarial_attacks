<style>

.reveal section img {
  border: 0px;
  box-shadow: 0 0 0 0;
}
.reveal table td {
  border: 0px;
}

.reveal table {
  border: 0px;
}

.reveal h1 {
  font-size: 2em;
}

.reveal h3 {
  font-size: 1.2em;
}

.reveal figcaption {
  font-size: 0.4em;
}

.small-code pre code {
  font-size: 1em;
}

.reveal .smalltext {
  font-size: 0.75em;
}

.reveal .mediumtext {
  font-size: 0.85em;
}

</style>


I'm a developer, why should I care about matrices or calculus?
========================================================
author: Sigrid Keydana, Trivadis
date: 
autosize: true
incremental:false
width: 1400
height: 900


About me & my employer
========================================================
class:mediumtext


<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

Trivadis
- DACH-based IT consulting and service company, from traditional technologies to big data/machine learning/data science

My background
- from psychology/statistics via software development and database engineering to data science and ML/DL

My passion
- machine learning and deep learning
- data science and (Bayesian) statistics
- explanation/understanding over prediction accuracy

Where to find me
- blog: http://recurrentnull.wordpress.com
- twitter: @zkajdan


========================================================
type:prompt

&nbsp; 

&nbsp; 

<h1>
Part 1: Why should I know about calculus?
</h1>


CIFAR-10 dataset
========================================================

&nbsp;

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',
                      echo=FALSE, warning=FALSE, message=FALSE,
                      cache = TRUE)
options(digits = 3, scipen = 6)
```

```{r}
library(ggplot2)
library(tidyr)
library(dplyr)
library(gridExtra)
library(ggfortify)
library(tensorflow)
library(keras)
K <- keras::backend()
library(EBImage)
source("load_frogs_ships.R")
source("functions.R")
```


10 classes, 32 x 32 px, popular benchmarking dataset for image recognition

&nbsp;

```{r}
layout(matrix(1:20, 4, 5))

for (i in 1:20) {
  img <- EBImage::transpose(Image(data = x_train[i, , , ], colormode = "Color"))
  display(img, method="raster", all = TRUE)
}

```


&nbsp;

Let's just pick two classes, keeping it simple...


Ship or frog?
========================================================

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />


&nbsp;

- We've trained a small Convolutional Neural Network (CNN) from scratch to distinguish between ships and frogs, specifically.
- After very few epochs, it tells both classes apart with more than 97% accuracy on the test set.
- Now let's pick some ship ...

```{r,  fig.width=3, fig.height=3}
poor_frog <- x_train_combined[9, , ,  ,drop = FALSE]
some_ship <- x_train_combined[5007, , ,  ,drop = FALSE]
poor_frog_img <- x_train_combined[9, , , ]
some_ship_img <- x_train_combined[5007, , , ] 

layout(1)
plot_as_image(some_ship_img)
```

&nbsp;

... and predict it's class probability:

&nbsp;

```{r}
model_name <- "frogs_ships_conv.h5"
model <- load_model_hdf5(model_name)
ship_prob <- model %>% predict_proba(some_ship)
paste("Predicted probability for ship: ", ship_prob)
```


So let's make a small change to that ship...
========================================================

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

```{r,fig.width=3, fig.height=3}
library(tensorflow)
library(keras)
K <- keras::backend()

model_name <- "frogs_ships_conv.h5"
model <- load_model_hdf5(model_name)

target <- model %>% predict_classes(some_ship)
target_variable = K$variable(target)

loss <- metric_binary_crossentropy(model$output, target_variable)
gradients <- K$gradients(loss, model$input) 
input <- model$input
output <- model$output
sess <- tf$Session()
sess$run(tf$global_variables_initializer())

evaluated_gradients <- sess$run(gradients,
                                feed_dict = dict(input = some_ship,
                                                 output = model %>% predict_proba(some_ship)))
ship_grads <- evaluated_gradients[[1]]
sgn_ship_grads <- sign(ship_grads)

adv <- some_ship + 0.123 * sgn_ship_grads
adv <- ifelse(adv > 1, 1, adv)
adv <- ifelse(adv < 0, 0, adv)
plot_as_image(adv[1, , , ])

new_ship_prob <- model %>% predict_proba(adv)
```

&nbsp;

... and see what the net says now:

&nbsp;

```{r}
print(paste("Predicted probability for ship: ", new_ship_prob))
```





What's going on?
========================================================
class:smallcode

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />


&nbsp;


Let's step back from more complicated architectures for a second and look at straightforward logistic regression (with Keras):

&nbsp;

```{r, eval=FALSE, echo=TRUE}
model <- keras_model_sequential()

model %>%
  layer_dense(units = 1, input_shape = 3072) %>%
  layer_activation("sigmoid")

model %>% compile(optimizer = optimizer_sgd(lr = 0.001), loss = "binary_crossentropy")
```


&nbsp;

When does this model say _frog_ (coded as 0) and when _ship_ (coded as 1)?




Logistic regression decision logic
========================================================

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />


&nbsp;

Logistic regression uses the _sigmoid_ function to decide which class to output, 0 or 1.

$sigmoid(x,w) = \frac{1}{1 + e^{-\mathbf{w}^T\mathbf{x} + b}}$



```{r, fig.width=8, fig.height=4}
sigmoid <- function(x) 1/(1 + exp(-x))
plot(-10:10, sigmoid(-10:10), type = "l")
```


When $\mathbf{w}^T\mathbf{x} + b$ > 0, sigmoid(x,w) > 0.5, and we get "ship" (1).

When $\mathbf{w}^T\mathbf{x} + b$ < 0, sigmoid(x,w) < 0.5, and we get "frog" (0).


So if we want the algorithm to say "0", for frog ...
========================================================

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />


&nbsp;


$sigmoid(x,w)= \frac{1}{1 + e^{-\mathbf{w}^T\mathbf{x} + b}}$ 

somehow has to end up < 0.5!

&nbsp;

&nbsp;

Let's take a small excerpt of this dot product, $\mathbf{w}^T\mathbf{x}$, and look how we could make it smaller:

&nbsp;

$w_1^Tx_1 + w_2^Tx_2 + w_3^Tx_3 ...$

&nbsp;


This will get smaller when for all positive $w_i$, we decrease $x_i$, and for all negative $w_i$, we increase $x_i$.


Let's do this!
========================================================

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />


&nbsp;

tbd get the weights


OK, but that was just simple logistic regression... 
========================================================

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />


&nbsp;

... what can we do when we have _deep neural networks_?

And thus: several layers of weights in the game?


<figure>
    <img src='deep_nn.png' width='60%' />
    <figcaption>Source: https://uwaterloo.ca/data-science/sites/ca.data-science/files/uploads/files/lecture_1_0.pdf</figcaption>
</figure>


Training a network, the evil way
========================================================

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

&nbsp;

Normal training has the network _get better_ in doing the _right_ classification.

How about we have it _get worse_, or put differently, have an _alternative definition of what is right_?



Minimizing the cost: Gradient Descent
========================================================

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

In optimization, normally we follow the gradient _downward_ to reach the/a minimum of the cost function.

&nbsp:

In this graphic, cost is a quadratic function, e.g., _mean squared error_:

&nbsp;

<figure>
    <img src='convex.png' width='50%'/>
     <figcaption>Source: Goodfellow et al. 2016, <a href='http://www.deeplearningbook.org/'>Deep Learning</a>
</figure>


Cost for logistic regression
========================================================

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

In two-class classification (be it shallow logistic regression or a deep convnet), the loss function to minimize is cross entropy:

$- \sum_j{t_j log(y_j)}$

Normally we'd try to minimize that cost function...


Being evil
========================================================

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

... now we _maximize_ the error instead of minimizing it!

&nbsp;

Let's step back for a second and see this how this works in context.



What a neural network needs for learning
========================================================

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

- a cost function: How different is my prediction from my target?
  (This we've seen already.)
- a way to learn (optimization): How do I adapt my _weights_ such that my predictions get better?
  (This we've looked at, too.)
- a way to back propagate the cost: How do weights _earlier_ in the network change the predictions (and thus, the cost)?

&nbsp;

Enter ...


<figure>
    <img src='deep_nn.png' width='20%' />
    <figcaption>Source: https://uwaterloo.ca/data-science/sites/ca.data-science/files/uploads/files/lecture_1_0.pdf</figcaption>
</figure>

Backpropagation!
========================================================

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

- basically, just the chain rule: $\frac{dz}{dx} = \frac{dz}{dy} \frac{dy}{dx}$
- chained over several layers:

&nbsp;

<figure>
    <img src='backprop2.png' width='60%'/>
    <figcaption>Source: <a href=https://colah.github.io/posts/2015-08-Backprop/>https://colah.github.io/posts/2015-08-Backprop/</a></figcaption>
</figure>


Learning weights by backpropagation (1)
========================================================

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp; 

We'll gradually build up the gradient of the loss with respect to $y_i$, the output of the last hidden layer, and the weights $w_{ij}$, respectively.


Here 
- $i$ and $j$ are layers of the network ($j$ being the output layer)
- $y_l$ is the output of layer $l$
- $z_l$ is the aggregated input going into layer $l$ (before the activation function is applied)

<figure>
    <img src='backprop4.png' width="20%"/>
    <figcaption>Source: tbd</a></figcaption>
</figure>

&nbsp;


Learning weights by backpropagation (2)
========================================================

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp; 

<figure>
    <img src='backprop4.png' width="20%"/>
    <figcaption>Source: tbd</a></figcaption>
</figure>

&nbsp;

Step 1:

At the output layer $j$, we compare class prediction and actual class, using cross entropy: $- \sum_n{t_n log(y_n)}$ 

The gradient $ ... $ describes how the error E changes as the prediction changes. 
   

Learning weights by backpropagation (2)
========================================================

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp; 

<figure>
    <img src='backprop4.png' width="20%"/>
    <figcaption>Source: tbd</a></figcaption>
</figure>

&nbsp;
  
2. Next is the question: How does the prediction/output change as the input to the final neuron (here: layer $j$) changes?

   In the case of a logistic (sigmoid) neuron, this is described by the gradient $...$
 
   


Backprop, the evil way...
========================================================

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />

&nbsp;

We can the same mechanics of loss calculation and backpropagation, just

- we change the input, not the weights
- we actually want to _maximize_ the loss

Climbing the gradient, fast (Fast Gradient Sign Method, FGSM)
========================================================

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />


&nbsp;

2 slides

tbd why it works

tbd effect




Takeaway: Optimization and Calculus
========================================================

<img src="tri_logo_high.jpg" style="position:absolute;top:0px;right:0px; width: 10%" />
<img src='cube3.png' border=0 style="position:absolute;top:90%;right:0px; width: 8%" />


&nbsp;


========================================================
type:prompt

&nbsp; 

&nbsp; 

<h1>
Part 2: Why should I know about matrices?
</h1>


